  0%|                                                                                                                                     | 0/3 [00:00<?, ?it/s]/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Traceback (most recent call last):
  File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent_metamath.py", line 356, in <module>
    trainer.train()
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2043, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 3485, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent_metamath.py", line 207, in compute_loss
    rational = model.generate(input_ids=inputs_ids_q_l, attention_mask=mask_q_l, \
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 1956, in generate
    prepared_stopping_criteria = self._get_stopping_criteria(
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 953, in _get_stopping_criteria
    criteria.append(StopStringCriteria(stop_strings=generation_config.stop_strings, tokenizer=tokenizer))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py", line 247, in __init__
    self.embedding_vec, self.max_valid_positions, self.max_valid_end_lens = self.clean_and_embed_tokens_with_cache(
                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py", line 263, in clean_and_embed_tokens_with_cache
    clean_token_list, clean_token_indices = self.clean_tokenizer_vocab(tokenizer)
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py", line 291, in clean_tokenizer_vocab
    token_string = tokenizer.convert_tokens_to_string(tokens_base + [token])
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py", line 640, in convert_tokens_to_string
    def convert_tokens_to_string(self, tokens: List[str]) -> str:

KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent_metamath.py", line 356, in <module>
[rank0]:     trainer.train()
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2043, in train
[rank0]:     return inner_training_loop(
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 3485, in training_step
[rank0]:     loss = self.compute_loss(model, inputs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent_metamath.py", line 207, in compute_loss
[rank0]:     rational = model.generate(input_ids=inputs_ids_q_l, attention_mask=mask_q_l, \
[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 1956, in generate
[rank0]:     prepared_stopping_criteria = self._get_stopping_criteria(
[rank0]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 953, in _get_stopping_criteria
[rank0]:     criteria.append(StopStringCriteria(stop_strings=generation_config.stop_strings, tokenizer=tokenizer))
[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py", line 247, in __init__
[rank0]:     self.embedding_vec, self.max_valid_positions, self.max_valid_end_lens = self.clean_and_embed_tokens_with_cache(
[rank0]:                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py", line 263, in clean_and_embed_tokens_with_cache
[rank0]:     clean_token_list, clean_token_indices = self.clean_tokenizer_vocab(tokenizer)
[rank0]:                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py", line 291, in clean_tokenizer_vocab
[rank0]:     token_string = tokenizer.convert_tokens_to_string(tokens_base + [token])
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py", line 640, in convert_tokens_to_string
[rank0]:     def convert_tokens_to_string(self, tokens: List[str]) -> str:

[rank0]: KeyboardInterrupt
