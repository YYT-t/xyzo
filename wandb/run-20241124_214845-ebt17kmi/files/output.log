  0%|                                                                                                                                     | 0/3 [00:00<?, ?it/s]/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
query_decode: ["Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points?", 'Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: What is the total cost of purchasing equipment for all sixteen players on the football team, considering that each player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80?', "Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points?", 'Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: What is the total cost of purchasing equipment for all sixteen players on the football team, considering that each player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80?']
rational_decode: ["Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points? Answer: The distance between two points in the complex plane is given by the formula: $$d = |z_1 - z_2|$$\n$$d = |(1+2i) - (-1+i)|$$\n$$d = |1+2i + 1-i|$$\n$$d = |2+i|$$", 'Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: What is the total cost of purchasing equipment for all sixteen players on the football team, considering that each player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80?\n\nAnswer: To find the total cost, we need to calculate the cost of each item and multiply it by the number of players.\nCost of jersey = $25 * 16 = $400\nCost of shorts = $15.20 * 16 = $243.20\nCost of socks = $6.80 * 16 = $108.80\nTotal cost = $400 + $243.20 + $108.80 = $752', "Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points? Answer: The distance between two points in the complex plane is given by the formula: $$d = |z_1 - z_2|$$\n$$d = |(1+2i) - (-1+i)|$$\n$$d = |1+2i + 1-i|$$\n$$d = |2+i|$$", 'Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: What is the total cost of purchasing equipment for all sixteen players on the football team, considering that each player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80?\n\nAnswer: To find the total cost, we need to calculate the cost of each item and multiply it by the number of players.\nCost of jersey = $25 * 16 = $400\nCost of shorts = $15.20 * 16 = $243.20\nCost of socks = $6.80 * 16 = $108.80\nTotal cost = $400 + $243.20 + $108.80 = $752']
answer_decode: ['The answer is \\sqrt{5}.', 'The answer is 752.', 'The answer is \\sqrt{5}.', 'The answer is 752.']
Token indices sequence length is longer than the specified maximum sequence length for this model (262 > 256). Running this sequence through the model will result in indexing errors
xz: tensor([     2,   1261,    573,   2872,   3482,    611,    573,   2412,   3287,
        235292,    108,   9413, 235292,  73605, 235349, 235256,   2001,   1503,
           919,   2149,  23246,  11187,   1178,  11270,   9149, 235349, 235256,
          2001,   1503, 235265,   1927,  11270,   9149,   3895,   1378,  11187,
          1401,   1070,   2001,   1503, 235269,   1284,   1134,    791,    476,
          2001,   1503,  11594,    573,   4191,    576,  40742, 235349, 235256,
        235265,  40742, 235349, 235256,   2247,   1503,    603,  40742,  25685,
        235265,   2250,   1767,  11187,    708,    575,  73605, 235349, 235256,
          2001,   1503, 235336,  10358, 235292,   2456,    708, 235248, 235310,
         11187,    575,  40742, 235349, 235256,   2001,   1503, 235269,    712,
         11270,   9149, 235349, 235256,   1503,    603, 235248, 235310, 235287,
        235284,    963, 235284,    589, 235248, 235274, 235276,  11187,   1497,
        235265,  73605, 235349, 235256,   2001,   1503,    603, 235248, 235304,
         11187,  25270,   1178,  11270,   9149, 235349, 235256, 235269,    712,
          1104,    708, 235248, 235274, 235276,    728, 235248, 235304,    589,
        235248, 235324,  11187,    575,  73605, 235349, 235256,   2001,   1503,
        235265,    108,   9413, 235292, 165522,    578,  12685,    708,  22623,
          5968,    611,    573,   5766,  10599, 235265,  12685,  56360,    573,
          2377,    697, 235274, 235340, 235284, 235252,   3306, 165522,  56360,
          6058, 235274, 235340, 235252,   3306,   2250,   2166,  10392,    708,
        165522,    578,  12685, 235303, 235256,   3782, 235336,  10358, 235292,
           714,   6075,   1865,   1378,   3782,    575,    573,   5766,  10599,
           603,   2764,    731,    573,  10513, 235292,  25874, 235258,    589,
          1420, 235306, 235298, 235274,    728,    868, 235298, 235284, 235371,
          4471,    108,   4471, 235258,    589,   1420, 235278, 235274, 235340,
        235284, 235252, 235275,    728,  15958, 235274, 235340, 235252,  31966,
          4471,    108,   4471, 235258,    589,   1420, 235274, 235340, 235284,
        235252,    963, 235248, 235274, 235290, 235252, 235371,   4471,    108,
          4471, 235258,    589,   1420, 235284, 235340, 235252, 235371,   4471,
           108,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1], device='cuda:0')
xz_labels: tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,  10358, 235292,
           714,   6075,   1865,   1378,   3782,    575,    573,   5766,  10599,
           603,   2764,    731,    573,  10513, 235292,  25874, 235258,    589,
          1420, 235306, 235298, 235274,    728,    868, 235298, 235284, 235371,
          4471,    108,   4471, 235258,    589,   1420, 235278, 235274, 235340,
        235284, 235252, 235275,    728,  15958, 235274, 235340, 235252,  31966,
          4471,    108,   4471, 235258,    589,   1420, 235274, 235340, 235284,
        235252,    963, 235248, 235274, 235290, 235252, 235371,   4471,    108,
          4471, 235258,    589,   1420, 235284, 235340, 235252, 235371,   4471,
           108,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100], device='cuda:0')
decode x:  <bos>Answer the question based on the following example:
Question: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.
Question: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points?<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>
decode xz:  <bos>Answer the question based on the following example:
Question: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.
Question: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points? Answer: The distance between two points in the complex plane is given by the formula: $$d = |z_1 - z_2|$$
$$d = |(1+2i) - (-1+i)|$$
$$d = |1+2i + 1-i|$$
$$d = |2+i|$$
<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>
decode xzy:  <bos>Answer the question based on the following example:
Question: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.
Question: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points? Answer: The distance between two points in the complex plane is given by the formula: $$d = |z_1 - z_2|$$
$$d = |(1+2i) - (-1+i)|$$
$$d = |1+2i + 1-i|$$
$$d = |2+i|$$
The answer is \sqrt{5}.<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>
/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
Could not estimate the number of tokens of the input, floating-point operations will not be computed
 33%|█████████████████████████████████████████▎                                                                                  | 1/3 [03:48<07:37, 228.58s/it]/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
query_decode: ["Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points?", 'Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: What is the total cost of purchasing equipment for all sixteen players on the football team, considering that each player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80?', "Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points?", 'Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: What is the total cost of purchasing equipment for all sixteen players on the football team, considering that each player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80?']
rational_decode: ["Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points? Answer: The distance between two points in the complex plane is given by the formula: $$d = |z_1 - z_2|$$\n$$d = |(1+2i) - (-1+i)|$$\n$$d = |1+2i + 1-i|$$\n$$d = |2+i|$$", 'Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: What is the total cost of purchasing equipment for all sixteen players on the football team, considering that each player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80?\n\nAnswer: To find the total cost, we need to calculate the cost of each item and multiply it by the number of players.\nCost of jersey = $25 * 16 = $400\nCost of shorts = $15.20 * 16 = $243.20\nCost of socks = $6.80 * 16 = $108.80\nTotal cost = $400 + $243.20 + $108.80 = $752', "Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points? Answer: The distance between two points in the complex plane is given by the formula: $$d = |z_1 - z_2|$$\n$$d = |(1+2i) - (-1+i)|$$\n$$d = |1+2i + 1-i|$$\n$$d = |2+i|$$", 'Answer the question based on the following example:\nQuestion: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.\nQuestion: What is the total cost of purchasing equipment for all sixteen players on the football team, considering that each player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80?\n\nAnswer: To find the total cost, we need to calculate the cost of each item and multiply it by the number of players.\nCost of jersey = $25 * 16 = $400\nCost of shorts = $15.20 * 16 = $243.20\nCost of socks = $6.80 * 16 = $108.80\nTotal cost = $400 + $243.20 + $108.80 = $752']
answer_decode: ['The answer is \\sqrt{5}.', 'The answer is 752.', 'The answer is \\sqrt{5}.', 'The answer is 752.']
xz: tensor([     2,   1261,    573,   2872,   3482,    611,    573,   2412,   3287,
        235292,    108,   9413, 235292,  73605, 235349, 235256,   2001,   1503,
           919,   2149,  23246,  11187,   1178,  11270,   9149, 235349, 235256,
          2001,   1503, 235265,   1927,  11270,   9149,   3895,   1378,  11187,
          1401,   1070,   2001,   1503, 235269,   1284,   1134,    791,    476,
          2001,   1503,  11594,    573,   4191,    576,  40742, 235349, 235256,
        235265,  40742, 235349, 235256,   2247,   1503,    603,  40742,  25685,
        235265,   2250,   1767,  11187,    708,    575,  73605, 235349, 235256,
          2001,   1503, 235336,  10358, 235292,   2456,    708, 235248, 235310,
         11187,    575,  40742, 235349, 235256,   2001,   1503, 235269,    712,
         11270,   9149, 235349, 235256,   1503,    603, 235248, 235310, 235287,
        235284,    963, 235284,    589, 235248, 235274, 235276,  11187,   1497,
        235265,  73605, 235349, 235256,   2001,   1503,    603, 235248, 235304,
         11187,  25270,   1178,  11270,   9149, 235349, 235256, 235269,    712,
          1104,    708, 235248, 235274, 235276,    728, 235248, 235304,    589,
        235248, 235324,  11187,    575,  73605, 235349, 235256,   2001,   1503,
        235265,    108,   9413, 235292, 165522,    578,  12685,    708,  22623,
          5968,    611,    573,   5766,  10599, 235265,  12685,  56360,    573,
          2377,    697, 235274, 235340, 235284, 235252,   3306, 165522,  56360,
          6058, 235274, 235340, 235252,   3306,   2250,   2166,  10392,    708,
        165522,    578,  12685, 235303, 235256,   3782, 235336,  10358, 235292,
           714,   6075,   1865,   1378,   3782,    575,    573,   5766,  10599,
           603,   2764,    731,    573,  10513, 235292,  25874, 235258,    589,
          1420, 235306, 235298, 235274,    728,    868, 235298, 235284, 235371,
          4471,    108,   4471, 235258,    589,   1420, 235278, 235274, 235340,
        235284, 235252, 235275,    728,  15958, 235274, 235340, 235252,  31966,
          4471,    108,   4471, 235258,    589,   1420, 235274, 235340, 235284,
        235252,    963, 235248, 235274, 235290, 235252, 235371,   4471,    108,
          4471, 235258,    589,   1420, 235284, 235340, 235252, 235371,   4471,
           108,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1,      1,      1,      1,      1,      1,
             1,      1,      1,      1], device='cuda:0')
xz_labels: tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,  10358, 235292,
           714,   6075,   1865,   1378,   3782,    575,    573,   5766,  10599,
           603,   2764,    731,    573,  10513, 235292,  25874, 235258,    589,
          1420, 235306, 235298, 235274,    728,    868, 235298, 235284, 235371,
          4471,    108,   4471, 235258,    589,   1420, 235278, 235274, 235340,
        235284, 235252, 235275,    728,  15958, 235274, 235340, 235252,  31966,
          4471,    108,   4471, 235258,    589,   1420, 235274, 235340, 235284,
        235252,    963, 235248, 235274, 235290, 235252, 235371,   4471,    108,
          4471, 235258,    589,   1420, 235284, 235340, 235252, 235371,   4471,
           108,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
          -100,   -100,   -100,   -100], device='cuda:0')
decode x:  <bos>Answer the question based on the following example:
Question: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.
Question: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points?<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>
decode xz:  <bos>Answer the question based on the following example:
Question: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.
Question: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points? Answer: The distance between two points in the complex plane is given by the formula: $$d = |z_1 - z_2|$$
$$d = |(1+2i) - (-1+i)|$$
$$d = |1+2i + 1-i|$$
$$d = |2+i|$$
<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>
decode xzy:  <bos>Answer the question based on the following example:
Question: Samantha’s last name has three fewer letters than Bobbie’s last name. If Bobbie took two letters off her last name, she would have a last name twice the length of Jamie’s. Jamie’s full name is Jamie Grey. How many letters are in Samantha’s last name? Answer: There are 4 letters in Jamie’s last name, so Bobbie’s name is 4*2 +2 = 10 letters long. Samantha’s last name is 3 letters shorter than Bobbie’s, so there are 10 - 3 = 7 letters in Samantha’s last name.
Question: Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points? Answer: The distance between two points in the complex plane is given by the formula: $$d = |z_1 - z_2|$$
$$d = |(1+2i) - (-1+i)|$$
$$d = |1+2i + 1-i|$$
$$d = |2+i|$$
The answer is \sqrt{5}.<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>
/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 67%|██████████████████████████████████████████████████████████████████████████████████▋                                         | 2/3 [08:23<04:16, 256.01s/it]/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
No files have been modified since last commit. Skipping to prevent empty commit.
Traceback (most recent call last):
  File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent_metamath.py", line 356, in <module>
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2043, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 3485, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent_metamath.py", line 207, in compute_loss
    inputs_ids_a_r = inputs["input_ids_a_r"][:, 1:]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 2047, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 3007, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1603, in _call_impl
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py", line 1069, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1603, in _call_impl
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py", line 870, in forward
    layer_outputs = self._gradient_checkpointing_func(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/_compile.py", line 31, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 600, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 481, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/autograd/function.py", line 574, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 255, in forward
    outputs = run_function(*args)
              ^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1603, in _call_impl
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py", line 604, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1603, in _call_impl
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py", line 342, in forward
    value_states = self.v_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1592, in _call_impl
    args_result = hook(self, args)
                  ^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py", line 278, in _pre_forward_module_hook
    self.pre_sub_module_forward_function(module)
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py", line 452, in pre_sub_module_forward_function
    param_coordinator.fetch_sub_module(sub_module, forward=True)
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 600, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/deepspeed/runtime/zero/partitioned_param_coordinator.py", line 308, in fetch_sub_module
    self.__ongoing_fetch_events.popleft().synchronize()
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/cuda/streams.py", line 225, in synchronize
    super().synchronize()
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent_metamath.py", line 356, in <module>
[rank0]:
[rank0]:     ^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2043, in train
[rank0]:     return inner_training_loop(
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 3485, in training_step
[rank0]:     loss = self.compute_loss(model, inputs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent_metamath.py", line 207, in compute_loss
[rank0]:     inputs_ids_a_r = inputs["input_ids_a_r"][:, 1:]
[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 2047, in generate
[rank0]:     result = self._sample(
[rank0]:              ^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 3007, in _sample
[rank0]:     outputs = self(**model_inputs, return_dict=True)
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1603, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py", line 1069, in forward
[rank0]:     outputs = self.model(
[rank0]:               ^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1603, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py", line 870, in forward
[rank0]:     layer_outputs = self._gradient_checkpointing_func(
[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/_compile.py", line 31, in inner
[rank0]:     return disable_fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 600, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 481, in checkpoint
[rank0]:     return CheckpointFunction.apply(function, preserve, *args)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/autograd/function.py", line 574, in apply
[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 255, in forward
[rank0]:     outputs = run_function(*args)
[rank0]:               ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1603, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py", line 604, in forward
[rank0]:     hidden_states, self_attn_weights, present_key_value = self.self_attn(
[rank0]:                                                           ^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1603, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py", line 342, in forward
[rank0]:     value_states = self.v_proj(hidden_states)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1592, in _call_impl
[rank0]:     args_result = hook(self, args)
[rank0]:                   ^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py", line 278, in _pre_forward_module_hook
[rank0]:     self.pre_sub_module_forward_function(module)
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/deepspeed/runtime/zero/parameter_offload.py", line 452, in pre_sub_module_forward_function
[rank0]:     param_coordinator.fetch_sub_module(sub_module, forward=True)
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 600, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/deepspeed/runtime/zero/partitioned_param_coordinator.py", line 308, in fetch_sub_module
[rank0]:     self.__ongoing_fetch_events.popleft().synchronize()
[rank0]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/cuda/streams.py", line 225, in synchronize
[rank0]:     super().synchronize()
[rank0]: KeyboardInterrupt
