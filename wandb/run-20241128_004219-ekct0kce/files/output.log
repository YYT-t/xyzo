trained_model_name: gemma-1.1-7b-it_gsm8k_ent0.05_beam1_dosampleFalse_temp1.0_estep__totalepoch1
/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Traceback (most recent call last):
  File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent.py", line 363, in <module>
    trainer.train()
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 3485, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent.py", line 210, in compute_loss
    rational = model.generate(input_ids=inputs_ids_q_l, attention_mask=mask_q_l, \
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 2047, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 3014, in _sample
    next_token_logits = outputs.logits.clone()[:, -1, :].float()
                        ^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent.py", line 363, in <module>
[rank1]:     trainer.train()
[rank1]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2052, in train
[rank1]:     return inner_training_loop(
[rank1]:            ^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
[rank1]:     tr_loss_step = self.training_step(model, inputs)
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/trainer.py", line 3485, in training_step
[rank1]:     loss = self.compute_loss(model, inputs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/cyc2202/xyzo/proj_file/xyzo/E_step_ent.py", line 210, in compute_loss
[rank1]:     rational = model.generate(input_ids=inputs_ids_q_l, attention_mask=mask_q_l, \
[rank1]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 2047, in generate
[rank1]:     result = self._sample(
[rank1]:              ^^^^^^^^^^^^^
[rank1]:   File "/home/cyc2202/anaconda3/envs/yuan/lib/python3.11/site-packages/transformers/generation/utils.py", line 3014, in _sample
[rank1]:     next_token_logits = outputs.logits.clone()[:, -1, :].float()
[rank1]:                         ^^^^^^^^^^^^^^^^^^^^^^
[rank1]: KeyboardInterrupt
